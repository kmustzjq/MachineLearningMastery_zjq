{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码演示1：卷积输出尺寸关系演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--inputs--\n",
      "tensor([[[[ 0.,  1.,  2.,  3.,  4.],\n",
      "          [ 5.,  6.,  7.,  8.,  9.],\n",
      "          [10., 11., 12., 13., 14.],\n",
      "          [15., 16., 17., 18., 19.],\n",
      "          [20., 21., 22., 23., 24.]]]])\n",
      "--filters--\n",
      "tensor([[[[1., 1.],\n",
      "          [1., 1.]]]])\n",
      "--outputs--\n",
      "tensor([[[[12., 16., 20., 24.],\n",
      "          [32., 36., 40., 44.],\n",
      "          [52., 56., 60., 64.],\n",
      "          [72., 76., 80., 84.]]]]) \n",
      "\n",
      "--outputs(stride=2)--\n",
      "tensor([[[[12., 20.],\n",
      "          [52., 60.]]]]) \n",
      "\n",
      "--outputs(padding=1)--\n",
      "tensor([[[[ 0.,  1.,  3.,  5.,  7.,  4.],\n",
      "          [ 5., 12., 16., 20., 24., 13.],\n",
      "          [15., 32., 36., 40., 44., 23.],\n",
      "          [25., 52., 56., 60., 64., 33.],\n",
      "          [35., 72., 76., 80., 84., 43.],\n",
      "          [20., 41., 43., 45., 47., 24.]]]]) \n",
      "\n",
      "--outputs(dilation=2)--\n",
      "tensor([[[[24., 28., 32.],\n",
      "          [44., 48., 52.],\n",
      "          [64., 68., 72.]]]]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "import torch.nn.functional as F \n",
    "\n",
    "# 卷积输出尺寸计算公式 o = (i + 2*p -k')//s  + 1 \n",
    "# 对空洞卷积 k' = d(k-1) + 1\n",
    "# o是输出尺寸，i 是输入尺寸，p是 padding大小， k 是卷积核尺寸， s是stride步长, d是dilation空洞参数\n",
    "\n",
    "inputs = torch.arange(0,25).view(1,1,5,5).float() # i= 5\n",
    "filters = torch.tensor([[[[1.0,1],[1,1]]]]) # k = 2\n",
    "\n",
    "outputs = F.conv2d(inputs, filters) # o = (5+2*0-2)//1+1 = 4\n",
    "outputs_s2 = F.conv2d(inputs, filters, stride=2)  #o = (5+2*0-2)//2+1 = 2\n",
    "outputs_p1 = F.conv2d(inputs, filters, padding=1) #o = (5+2*1-2)//1+1 = 6\n",
    "outputs_d2 = F.conv2d(inputs,filters, dilation=2) #o = (5+2*0-(2(2-1)+1))//1+1 = 3\n",
    "\n",
    "print(\"--inputs--\")\n",
    "print(inputs)\n",
    "print(\"--filters--\")\n",
    "print(filters)\n",
    "\n",
    "print(\"--outputs--\")\n",
    "print(outputs,\"\\n\")\n",
    "\n",
    "print(\"--outputs(stride=2)--\")\n",
    "print(outputs_s2,\"\\n\")\n",
    "\n",
    "print(\"--outputs(padding=1)--\")\n",
    "print(outputs_p1,\"\\n\")\n",
    "\n",
    "print(\"--outputs(dilation=2)--\")\n",
    "print(outputs_d2,\"\\n\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码演示2：卷积层参数数量演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "features.shape: torch.Size([8, 64, 128, 128])\n",
      "\n",
      "\n",
      "--conv--\n",
      "conv_out.shape: torch.Size([8, 32, 126, 126])\n",
      "conv.weight.shape: torch.Size([32, 64, 3, 3])\n",
      "\n",
      "\n",
      "--group conv--\n",
      "group_out.shape: torch.Size([8, 32, 126, 126])\n",
      "conv_group.weight.shape: torch.Size([32, 8, 3, 3])\n",
      "\n",
      "\n",
      "--separable conv--\n",
      "separable_out.shape: torch.Size([8, 32, 126, 126])\n",
      "depth_conv.weight.shape: torch.Size([64, 1, 3, 3])\n",
      "oneone_conv.weight.shape: torch.Size([32, 64, 1, 1])\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "features = torch.randn(8,64,128,128)\n",
    "print(\"features.shape:\",features.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "#普通卷积\n",
    "print(\"--conv--\")\n",
    "conv = nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3)\n",
    "conv_out = conv(features)\n",
    "print(\"conv_out.shape:\",conv_out.shape) \n",
    "print(\"conv.weight.shape:\",conv.weight.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "#分组卷积\n",
    "print(\"--group conv--\")\n",
    "conv_group = nn.Conv2d(in_channels=64,out_channels=32,kernel_size=3,groups=8)\n",
    "group_out = conv_group(features)\n",
    "print(\"group_out.shape:\",group_out.shape) \n",
    "print(\"conv_group.weight.shape:\",conv_group.weight.shape)\n",
    "print(\"\\n\")\n",
    "\n",
    "#深度可分离卷积\n",
    "print(\"--separable conv--\")\n",
    "depth_conv = nn.Conv2d(in_channels=64,out_channels=64,kernel_size=3,groups=64)\n",
    "oneone_conv = nn.Conv2d(in_channels=64,out_channels=32,kernel_size=1)\n",
    "separable_conv = nn.Sequential(depth_conv,oneone_conv)\n",
    "separable_out = separable_conv(features)\n",
    "print(\"separable_out.shape:\",separable_out.shape) \n",
    "print(\"depth_conv.weight.shape:\",depth_conv.weight.shape)\n",
    "print(\"oneone_conv.weight.shape:\",oneone_conv.weight.shape)\n",
    "print(\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 代码演示3：上采样层"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inputs:\n",
      "tensor([[[[1., 2.],\n",
      "          [3., 4.]]]])\n",
      "\n",
      "\n",
      "nearest(inputs)：\n",
      "tensor([[[[1., 1., 2., 2.],\n",
      "          [1., 1., 2., 2.],\n",
      "          [3., 3., 4., 4.],\n",
      "          [3., 3., 4., 4.]]]])\n",
      "\n",
      "\n",
      "bilinear(inputs)：\n",
      "tensor([[[[1.0000, 1.3333, 1.6667, 2.0000],\n",
      "          [1.6667, 2.0000, 2.3333, 2.6667],\n",
      "          [2.3333, 2.6667, 3.0000, 3.3333],\n",
      "          [3.0000, 3.3333, 3.6667, 4.0000]]]])\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "from torch import nn \n",
    "\n",
    "inputs = torch.arange(1, 5, dtype=torch.float32).view(1, 1, 2, 2)\n",
    "print(\"inputs:\")\n",
    "print(inputs)\n",
    "print(\"\\n\")\n",
    "\n",
    "nearest = nn.Upsample(scale_factor=2, mode='nearest')\n",
    "bilinear = nn.Upsample(scale_factor=2,mode=\"bilinear\",align_corners=True)\n",
    "\n",
    "print(\"nearest(inputs)：\")\n",
    "print(nearest(inputs))\n",
    "print(\"\\n\")\n",
    "print(\"bilinear(inputs)：\")\n",
    "print(bilinear(inputs)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch\n",
    "PyTorch 的前身是 Torch，其底层和 Torch 框架一样，但是使用 Python 重新写了很多内容，不仅更加灵活，支持动态图，而且提供了 Python 接口。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n"
     ]
    }
   ],
   "source": [
    "# 导入库\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor, Lambda, Compose\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# 模型构建\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(\"Using {} device\".format(device))\n",
    "\n",
    "# Define model\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(28*28, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 10),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        logits = self.linear_relu_stack(x)\n",
    "        return logits\n",
    "\n",
    "model = NeuralNetwork().to(device)\n",
    "\n",
    "# 损失函数和优化器\n",
    "loss_fn = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=1e-3)\n",
    "\n",
    "# 模型训练\n",
    "def train(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        X, y = X.to(device), y.to(device)\n",
    "\n",
    "        # Compute prediction error\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        # Backpropagation\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * len(X)\n",
    "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('MachineLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7e1cbe28ed3875f6a4214958609dcad181c488131a7cb4b31ea2dac398219a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
