{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 在 Python 中使用 XGBoost 调整梯度提升的学习率"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 在 XGBoost 中调整学习率"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data[:, 1:3], iris.target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.231555 using {'learning_rate': 0.1}\n",
      "-1.086171 (0.000869) with: {'learning_rate': 0.0001}\n",
      "-0.983302 (0.008330) with: {'learning_rate': 0.001}\n",
      "-0.448460 (0.062565) with: {'learning_rate': 0.01}\n",
      "-0.231555 (0.240100) with: {'learning_rate': 0.1}\n",
      "-0.258177 (0.274780) with: {'learning_rate': 0.2}\n",
      "-0.285556 (0.298395) with: {'learning_rate': 0.3}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\Anaconda\\envs\\MachineLearning\\lib\\site-packages\\ipykernel_launcher.py:38: UserWarning: Matplotlib is currently using agg, which is a non-GUI backend, so cannot show the figure.\n"
     ]
    }
   ],
   "source": [
    "# XGBoost on Otto dataset, Tune learning_rate\n",
    "from pandas import read_csv\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot\n",
    "# # load data\n",
    "# data = read_csv('train.csv')\n",
    "# dataset = data.values\n",
    "# # split data into X and y\n",
    "# X = dataset[:,0:94]\n",
    "# y = dataset[:,94]\n",
    "# # encode string class values as integers\n",
    "# label_encoded_y = LabelEncoder().fit_transform(y)\n",
    "# grid search\n",
    "model = XGBClassifier()\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "param_grid = dict(learning_rate=learning_rate)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=1, cv=kfold)\n",
    "# grid_result = grid_search.fit(X, label_encoded_y)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "# plot\n",
    "pyplot.errorbar(learning_rate, means, yerr=stds)\n",
    "pyplot.title(\"XGBoost learning_rate vs Log Loss\")\n",
    "pyplot.xlabel('learning_rate')\n",
    "pyplot.ylabel('Log Loss')\n",
    "pyplot.savefig('learning_rate.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 调整 XGBoost 中的学习率和树的数量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: -0.207794 using {'learning_rate': 0.1, 'n_estimators': 40}\n",
      "-1.097358 (0.000087) with: {'learning_rate': 0.0001, 'n_estimators': 10}\n",
      "-1.096107 (0.000175) with: {'learning_rate': 0.0001, 'n_estimators': 20}\n",
      "-1.094857 (0.000262) with: {'learning_rate': 0.0001, 'n_estimators': 30}\n",
      "-1.093610 (0.000349) with: {'learning_rate': 0.0001, 'n_estimators': 40}\n",
      "-1.092364 (0.000436) with: {'learning_rate': 0.0001, 'n_estimators': 50}\n",
      "-1.086166 (0.000870) with: {'learning_rate': 0.001, 'n_estimators': 10}\n",
      "-1.073935 (0.001730) with: {'learning_rate': 0.001, 'n_estimators': 20}\n",
      "-1.061915 (0.002582) with: {'learning_rate': 0.001, 'n_estimators': 30}\n",
      "-1.050100 (0.003425) with: {'learning_rate': 0.001, 'n_estimators': 40}\n",
      "-1.038488 (0.004260) with: {'learning_rate': 0.001, 'n_estimators': 50}\n",
      "-0.982845 (0.008361) with: {'learning_rate': 0.01, 'n_estimators': 10}\n",
      "-0.884552 (0.015968) with: {'learning_rate': 0.01, 'n_estimators': 20}\n",
      "-0.800174 (0.022982) with: {'learning_rate': 0.01, 'n_estimators': 30}\n",
      "-0.727342 (0.029633) with: {'learning_rate': 0.01, 'n_estimators': 40}\n",
      "-0.664205 (0.035890) with: {'learning_rate': 0.01, 'n_estimators': 50}\n",
      "-0.439933 (0.063823) with: {'learning_rate': 0.1, 'n_estimators': 10}\n",
      "-0.267421 (0.104795) with: {'learning_rate': 0.1, 'n_estimators': 20}\n",
      "-0.216735 (0.143612) with: {'learning_rate': 0.1, 'n_estimators': 30}\n",
      "-0.207794 (0.175739) with: {'learning_rate': 0.1, 'n_estimators': 40}\n",
      "-0.209032 (0.197490) with: {'learning_rate': 0.1, 'n_estimators': 50}\n"
     ]
    }
   ],
   "source": [
    "# XGBoost on Otto dataset, Tune learning_rate and n_estimators\n",
    "from pandas import read_csv\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "from matplotlib import pyplot\n",
    "import numpy\n",
    "# # load data\n",
    "# data = read_csv('train.csv')\n",
    "# dataset = data.values\n",
    "# # split data into X and y\n",
    "# X = dataset[:,0:94]\n",
    "# y = dataset[:,94]\n",
    "# # encode string class values as integers\n",
    "# label_encoded_y = LabelEncoder().fit_transform(y)\n",
    "# # grid search\n",
    "model = XGBClassifier()\n",
    "n_estimators = [10, 20, 30, 40, 50]\n",
    "learning_rate = [0.0001, 0.001, 0.01, 0.1]\n",
    "param_grid = dict(learning_rate=learning_rate, n_estimators=n_estimators)\n",
    "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=7)\n",
    "grid_search = GridSearchCV(model, param_grid, scoring=\"neg_log_loss\", n_jobs=1, cv=kfold)\n",
    "# grid_result = grid_search.fit(X, label_encoded_y)\n",
    "grid_result = grid_search.fit(X, y)\n",
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "\tprint(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "# plot results\n",
    "scores = numpy.array(means).reshape(len(learning_rate), len(n_estimators))\n",
    "for i, value in enumerate(learning_rate):\n",
    "    pyplot.plot(n_estimators, scores[i], label='learning_rate: ' + str(value))\n",
    "pyplot.legend()\n",
    "pyplot.xlabel('n_estimators')\n",
    "pyplot.ylabel('Log Loss')\n",
    "pyplot.savefig('n_estimators_vs_learning_rate.png')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.12 ('MachineLearning')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d7e1cbe28ed3875f6a4214958609dcad181c488131a7cb4b31ea2dac398219a6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
